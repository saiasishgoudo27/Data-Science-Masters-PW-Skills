{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87238c1-64c1-46f6-b156-9947d689f1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data. \"\"\"\n",
    "Ans.\n",
    "    Web scraping is the automated extraction of data from websites. It involves using programs or\n",
    "    tools to access web pages, parse their content, and extract specific information. By sending requests\n",
    "    and analyzing the HTML or XML code, data like text, tables, images, or links can be gathered.\n",
    "    Web scraping saves time by automating data retrieval for analysis or integration.\n",
    "    It is crucial to consider legal and ethical aspects, respecting website terms of service and\n",
    "    privacy policies when conducting web scraping.\n",
    "    \n",
    "    \n",
    "    Web scraping is used to automate the extraction of data from websites. It saves time and effort\n",
    "    by collecting specific information from multiple websites in a structured format. This data can be used \n",
    "    for various purposes, such as research, analysis, monitoring, or integration with other systems.\n",
    "    \n",
    " I. E-commerce: \n",
    "        Web scraping is employed to gather product information, prices, customer reviews, and competitor\n",
    "        data for price comparison, market analysis, and dynamic pricing strategies\n",
    " II. Research and Market Intelligence:\n",
    "        Web scraping is utilized to collect data for market research, sentiment analysis, trend monitoring,\n",
    "        and gathering public data for academic or business research purposes.\n",
    " III. Real Estate and Property Listings:\n",
    "        Web scraping is used to extract data from real estate websites, including property listings,\n",
    "        prices, location information, and agent details, and informed decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9879cb-77d0-413e-b5d5-2543b07b8c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q2. What are the different methods used for Web Scraping?\"\"\"\n",
    "\n",
    "Ans.\n",
    "    Python Libraries\n",
    "    API Access\n",
    "    Web Scraping Framework\n",
    "    Text Extraction Libraries\n",
    "    Web Scraping Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaeb3cc-692a-404f-a849-73aac6221cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q3. What is Beautiful Soup? Why is it used?\"\"\"\n",
    "\n",
    "Ans.\n",
    "    Beautiful Soup is a Python library used for web scraping.\\\n",
    "    It helps parse HTML or XML documents, making it easier to extract specific data from\n",
    "    web pages by searching for elements, tags, or attributes.\n",
    "    \n",
    "    Beautiful Soup is used in web scraping to parse HTML or XML documents and extract specific data \n",
    "    from web pages. It simplifies the process by providing methods to navigate the document structure,\n",
    "    search for elements, & extract desired information, making web scraping tasks easier & more efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd4c145-bc62-4de6-812c-e4cb83f6cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q4. Why is flask used in this Web Scraping project?\"\"\"\n",
    "\n",
    "Ans.\n",
    "     It allows developers to quickly build web applications and APIs,\n",
    "    making it easy to create a user interface or expose the scraped data.\n",
    "    Flask also provides routing, request handling, and template rendering, making \n",
    "    it a convenient choice for displaying and interacting with the scraped data in a web-based format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226f85b-c6e5-4541-a5e1-33e14b4be724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\"\"\"\n",
    "\n",
    "Ans.\n",
    " 1. Amazon EC2 (Elastic Compute Cloud): \n",
    "        EC2 provides virtual servers in the cloud and can be used to host the web scraping application.\n",
    "        It offers scalable compute capacity and enables the deployment of the scraping code.\n",
    "    \n",
    " 2. Amazon S3 (Simple Storage Service):\n",
    "        S3 is object storage that can be used to store the scraped data. It provides a scalable and\n",
    "        secure storage solution for storing large volumes of data generated from web scraping.\n",
    "        \n",
    " 3. AWS Lambda: \n",
    "        Lambda is a serverless computing service that allows running code without  managing servers.\n",
    "        It can be used to execute scraping tasks or as part of a serverless architecture for data processing.\n",
    "        \n",
    " 4. AWS Glue: \n",
    "        Glue is a fully managed extract, transform, and load (ETL) service. It can be used for data \n",
    "        transformation, cleaning, and preparation after scraping the data, enabling seamless\n",
    "        integration with other AWS services or databases.\n",
    "        \n",
    " 5. AWS CloudFormation: \n",
    "        CloudFormation is an infrastructure-as-code service that enables the provisioning and management\n",
    "        of AWS resources. It can be used to define and deploy the entire infrastructure needed for\n",
    "        the web scraping project, including EC2 instances, storage, and networking components."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
